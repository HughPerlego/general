#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu May  4 17:07:38 2023

@author: hughwaters
"""

import os 
os.chdir('/Users/hughwaters/Desktop/Per Experinemnts/Per 3.5 /Final')

import pandas as pd
import datetime


base_path = '/Users/hughwaters/Desktop/Per Experinemnts/Per 3.5 /Decesions/type=decisions/'

start_date = pd.to_datetime("2023-09-05")
end_date = pd.to_datetime("2023-10-03")
date_range = pd.date_range(start_date, end_date)


dfs = []  # to hold dataframes from each parquet file

for date in date_range:
    folder_name = f"date={date.strftime('%Y-%m-%d')}"
    experiment_folder = "experiment=25118850148/"
    full_folder_path = os.path.join(base_path, folder_name, experiment_folder)
    
    for file in os.listdir(full_folder_path):
        if file.endswith(".parquet"):
            file_path = os.path.join(full_folder_path, file)
            df = pd.read_parquet(file_path)
            dfs.append(df)


df = pd.concat(dfs, ignore_index=True)


# Print the contents of the DataFrame & check for null / duplicated values 

df.dtypes
df.head(5)

df.isnull().sum()
df.duplicated().sum()


# Check each variation_id only has one experinment  

experinment_variations = df.groupby(['experiment_id', 'variation_id']).count()
experinment_variations

# check each visitor id only has one variation & experinment 


visitor_experinemnt_variations = df.groupby(['visitor_id'])['experiment_id'].nunique()
visitor_experinemnt_variations.sort_values(ascending = False)


visitor_variations = df.groupby(['visitor_id'])['variation_id'].nunique().reset_index()
visitor_variations.sort_values(by = 'variation_id', ascending = False)

visitor_variations_double = visitor_variations[visitor_variations['variation_id'] > 1]
visitor_variations_double = visitor_variations_double['visitor_id']

# exlcude visitor ids which have been assigned two variations 

merged = df.merge(visitor_variations_double, on=['visitor_id', 'visitor_id'], how='outer', indicator=True)
df_filtered = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])


# check all days have records & unique dates 

import numpy as np

df_filtered['record_timestamp'] = df_filtered['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')
df_filtered['timestamp_2'] = pd.to_datetime(df_filtered['record_timestamp'])
result_date_group = df_filtered.groupby(df_filtered['timestamp_2'].dt.date).count()
result_date_group.to_csv('date_row_check.csv')


# Select relevant fields for the experiment 

df_filtered= df_filtered[['uuid', 'record_timestamp' ,'visitor_id', 'experiment_id','variation_id']].reset_index(drop = True)


df_filtered.to_csv('optimizely_visitors_data_per_3_5.csv', index=False, header= False)


df_filtered.columns
